*Thinking...*

> Let me break down the requirements:
> 
> 1. `rowData` state with max 300 items (FIFO)
> 2. `handleMsg` callback receives websocket messages
> 3. Message structure: `{ time, stockId }`
> 4. Table displays: `time, stockId, repliedTime, qty, price`
> 5. Only one unreplied row per stockId (latest replaces first), max 2 rows per stockId (1 unreplied + 1 replied)
> 6. After submission:
>    - Update row with repliedTime, qty, price
>    - If `isExpiry` is false and `ttl` has value, remove row after `ttl` seconds and call `cancelOrder()`
> 
> Performance considerations:
> - Minimize memory usage
> - Minimize event loop usage (setTimeout)
> - Use efficient data structures
> - Store ttl and isExpiry separately from rowData
> 
> Let me design an efficient solution:
> 
> ### Data Structures:
> 
> 1. **rowData** - Array of display items: `{ id, time, stockId, repliedTime, qty, price }`
>    - Need a unique id for each row to track them
> 
> 2. **unrepliedMap** - Map<stockId, rowId> - Quick lookup for unreplied rows per stockId
>    - This helps us quickly find and remove the old unreplied row when a new one comes
> 
> 3. **repliedMap** - Map<stockId, rowId> - Quick lookup for replied rows per stockId
>    - This helps enforce the max 2 per stockId rule
> 
> 4. **ttlMap** - Map<rowId, { timerId, ttl, isExpiry }> - Store TTL info outside rowData
>    - Only create setTimeout when needed
> 
> 5. **rowCount** - Map<stockId, { unreplied: number, replied: number }> - Track counts per stockId
> 
> Wait, let me reconsider. The requirements say:
> - Only one unreplied row per stockId (the first one will be removed, and the latest will insert into the end)
> 
> 
> - Max 2 rows per stockId (one non-replied, one replied)
> 
> So for each stockId, I can maintain at most one unreplied row and one replied row. I'll use maps to track which row belongs to each stockId in each state, and a separate map to manage any active timers for TTL cleanup.
> 
> When a new message arrives, I generate a unique ID and check if an unreplied row already exists for that stockId—if so, I remove it before adding the new one. The rowData array stays capped at 300 items using FIFO eviction. When a row gets submitted, I locate it, update its fields, and transition it from the unreplied map to the replied map. If the array exceeds capacity, the oldest entry gets removed.
> 
> The tricky part is identifying which row the callback refers to. Since `onRowSubmit` receives user input from the dialog, I need to pass the row identifier when opening it, then have the callback return that same identifier along with the new qty, price, and ttl values so I can match it back to the correct entry in rowData.
> 
> I'll generate a unique ID for each row to handle this reliably. Then I can track pending orders by stockId and use the ID to locate and update or remove rows as needed.
> 
> ```javascript
> import { useCallback, useRef, useState } from 'react';
> 
> let idCounter = 0;
> const generateId = () => ++idCounter;
> 
> function useRowDataManager() {
>     const [rowData, setRowData] = useState([]);
>     
>     // Using refs to store maps that track state without causing re-renders
>     const unrepliedMapRef = useRef(new Map()); // stockId -> rowId
>     const repliedMapRef = useRef(new Map()); // stockId -> rowId
>     const rowIndexMapRef = useRef(new Map()); // rowId -> index in rowData
>     const ttlTimersRef = useRef(new Map()); // rowId -> { timerId, ttl }
>     
>     const handleMsg = useCallback((msg) => {
>         setRowData(prevRowData => {
>             const newRowData = [...prevRowData];
>             const unrepliedMap = unrepliedMapRef.current;
>             const repliedMap = repliedMapRef.current;
>             
>             const stockId = msg.stockId;
>             const newRowId = generateId();
>             
>             // If this stock already has an unreplied message, remove it first
>             if (unrepliedMap.has(stockId)) {
>                 const existingRowId = unrepliedMap.get(stockId);
>                 const existingIndex = newRowData.findIndex(r => r.id === existingRowId);
>                 if (existingIndex !== -1) {
>                     newRowData.splice(existingIndex, 1);
>                 }
>                 // Cancel any pending timeout for the old row
>                 if (ttlTimersRef.current.has(existingRowId)) {
>                     clearTimeout(ttlTimersRef.current.get(existingRowId).timerId);
>                     ttlTimersRef.current.delete(existingRowId);
>                 }
>             }
> ```
> 
> I'm handling incoming messages by checking if there's already an unreplied entry for that stock ID. If one exists, I remove the old row from the data and clear any associated timeout before adding the new message. removed.stockId);
>                 }
>                 if (ttlTimersRef.current.has(removed.id)) {
>                     clearTimeout(ttlTimersRef.current.get(removed.id).timerId);
>                     ttlTimersRef.current.delete(removed.id);
>                 }
>             }
>             
>             return newRowData;
>         });
>     }, []);
> }
> ```
> 
> I'm noticing a performance concern—calling `findIndex` on every message creates O(n) lookups, which becomes problematic with frequent updates. I should consider using `useReducer` for cleaner state transitions or maintaining an index map in a ref to achieve O(1) lookups instead.
> 
> The challenge with an index map is that array indices shift when items are removed. A better approach might be switching to a Map as the primary data structure for O(1) access, then deriving the display array from it. I'd store rows by ID in a Map, maintain separate Maps for tracking unreplied and replied items by stock ID, and keep an order array to preserve FIFO sequencing.
> 
> But this introduces significant complexity. Given the constraints—max 300 items and WebSocket message rates that are unlikely to be extreme—O(n) performance with n=300 is acceptable. I should focus on correctness rather than premature optimization.
> 
> Looking at the actual requirement again: each stockId can display at most 2 items (one unreplied, one replied). This means when a new message arrives for a stockId, if there's already an unreplied message, the new one replaces it.
> 
> When a message transitions to replied status, the old replied message for that stockId should be removed, leaving only the newly replied one. The constraint allows for one unreplied and one replied per stockId simultaneously, but replacing older messages of the same type maintains that limit. replied
> - If an old replied entry exists, it gets removed to keep the limit at 1 replied per stockId
> 
> For the TTL logic, when isExpiry is false and a ttl value exists, the row should be removed after that many seconds elapse. If isExpiry is true, the row persists regardless of TTL. I should store ttl and isExpiry separately from rowData to keep things organized.
> 
> On performance, I need to be mindful about minimizing setTimeout calls and memory usage. Rather than creating individual timers for each row, I could consolidate the timer management approach. a single interval checking every second seems most practical given typical TTL values around 30 seconds and multiple rows with varying expiration times.
> 
> I'll implement this with a single setInterval that runs every second and checks all rows with TTL, removing any that have expired. The approach stores an expirationTime for each row rather than a countdown, making the expiration check straightforward. I'll also set up quick lookup maps for unreplied and replied rows to efficiently manage state updates. // TTL storage: rowId -> { expirationTime, uniqueOrderId }
> const ttlDataRef = useRef(new Map());
> 
> // Handle incoming WebSocket message
> const handleMsg = useCallback((msg) => {
>     const { time, stockId } = msg;
>     const newRowId = generateRowId();
>     
>     setRowData(prevRowData => {
>         let newRowData = [...prevRowData];
>         const unrepliedMap = unrepliedMapRef.current;
>         const repliedMap = repliedMapRef.current;
>         const ttlData = ttlDataRef.current;
>         
>         // Remove existing unreplied row for this stockId if exists
>         const existingUnrepliedId = unrepliedMap.get(stockId);
>         if (existingUnrepliedId) {
>             newRowData = newRowData.filter(r => r.id !== existingUnrepliedId);
>             ttlData.delete(existingUnrepliedId);
>         }
>         
>         // Create new row
>         const newRow = {
>             id: newRowId,
>             time,
>             stockId,
>             repliedTime: null,
>             qty: null,
>             price: null
>         };
>         
>         newRowData.push(newRow);
>         unrepliedMap.set(stockId, newRowId);
>         
>         // FIFO: enforce max 300 items
>         while (newRowData.length > 300) {
>             const removed = newRowData.shift();
>             // Clean up maps based on which category the removed row belonged to
>             if (unrepliedMap.get(removed.stockId) === removed.id) {
>                 unrepliedMap.delete(removed.stockId);
>             }
>             if (repliedMap.get(removed.stockId) === removed.id) {
>                 repliedMap.delete(removed.stockId);
>             }
>             ttlData.delete(removed.id);
>         }
>         
>         return newRowData;
>     });
> }, []);
> 
> // Handle row submission (user replied)
> const onRowSubmit = useCallback((row) => {
>     const { id: rowId, stockId, qty, price, ttl, isExpiry } = row;
>     const repliedTime = Date.now();
>     
>     setRowData(prevRowData => {
>         let newRowData = [...prevRowData];
>         const unrepliedMap = unrepliedMapRef.current;
>         const repliedMap = repliedMapRef.current;
>         const ttlData = ttlDataRef.current;
>         
>         // Remove any existing replied row for this stockId
>         const existingRepliedId = repliedMap.get(stockId);
>         if (existingRepliedId) {
>             newRowData = newRowData.filter(r => r.id !== existingRepliedId);
>             ttlData.delete(existingRepliedId);
>         }
>         
>         // Update the submitted row with reply details
> 
> When a user submits a row, I'm checking if there's already a replied entry for that stock and removing it, then updating the current row with the submission details.
> 
>         const rowIndex = newRowData.findIndex(r => r.id === rowId);
>         if (rowIndex !== -1) {
>             newRowData[rowIndex] = {
>                 ...newRowData[rowIndex],
>                 repliedTime,
>                 qty,
>                 price
>             };
>             
>             // Shift the row from unreplied to replied tracking
>             unrepliedMap.delete(stockId);
>             repliedMap.set(stockId, rowId);
>             
>             // Configure TTL expiration for non-expiry orders
>             if (!isExpiry && ttl) {
>                 const expirationTime = Date.now() + ttl * 1000;
>                 const uniqueOrderId = `order_${rowId}`;
>                 ttlData.set(rowId, { expirationTime, uniqueOrderId });
>             }
>         }
>         
>         return newRowData;
> 
> I'm updating the maps to track which rows are replied versus unreplied, and setting up a TTL timer for orders that need automatic expiration. has(r.id));
>                     
>                     expiredRowIds.forEach(({ rowId }) => {
>                         ttlData.delete(rowId);
>                         const row = prevRowData.find(r => r.id === rowId);
>                         if (row) {
>                             repliedMapRef.current.delete(row.stockId);
>                         }
>                     });
>                     
>                     return newRowData;
>                 });
>             }
>         }, 1000);
>         
>         return () => clearInterval(intervalId);
>     }, [cancelOrder]);
>     
>     return { rowData, handleMsg, onRowSubmit };
> }
> 
> After removing expired entries from the state, I need to clean up the associated data structures—deleting from ttlData and removing any corresponding entries from repliedMapRef. The interval runs every second and gets properly cleared on unmount, with cancelOrder as a dependency to ensure the latest version is used.
> 
> Since the user mentioned the display component and websocket logic are already in place, I should focus on providing the constraint handling logic. The `handleMsg` function needs to properly add incoming messages to rowData without mutating state directly, and `onRowSubmit` should handle the callback when a row's dialog submission completes.
> 
> Looking at how the dialog integrates with the data flow: when a user double-clicks a row to open the dialog, the system needs to track which row was edited. Since there's only one unreplied row per stockId at any time, the callback likely receives the stockId along with the submitted values (qty, price, ttl, isExpiry), then updates that specific row in rowData and applies the TTL constraint.
> 
> For performance, I should prioritize a few key strategies: using Maps instead of arrays for constant-time lookups by stockId, consolidating TTL expiration checks into a single interval rather than individual timers, and leveraging refs to hold mutable state that shouldn't trigger re-renders.
> 
> When a row gets removed by the FIFO mechanism, no cancelOrder request should fire—only TTL expiration triggers that call. If a new message arrives for the same stockId and replaces an unreplied row, that's straightforward since unreplied rows don't have TTL anyway. The trickier case is when submitting a reply replaces an existing replied row—I need to clarify whether cancelOrder should be invoked in that scenario based on the TTL requirement.
> 
> The specification is explicit: cancelOrder only fires when TTL triggers, not during other removal scenarios. So when replacing a replied row with a new one, I should clear its TTL data and remove it from display without calling cancelOrder. If I don't clear the TTL data, the interval will still attempt to process it even after the row is gone from rowData, potentially triggering an unwanted cancelOrder call. The distinction matters: explicit removal (replacement) skips cancelOrder entirely, while TTL expiration is the only path that invokes it.
> 
> I need to ensure that when a row is explicitly removed, its associated TTL data gets deleted. The implementation should use a custom hook that manages row data with these constraints, likely using maps for efficient lookups and an interval to handle TTL expiration.
> 
> Maps stored in refs prevent unnecessary re-renders while tracking unreplied and replied rows by stock ID. A separate TTL tracker maps row IDs to their expiration times and order IDs. When messages arrive, the handler generates unique IDs and updates the appropriate maps based on whether a stock already has an active row.
> 
> If an unreplied row exists for the incoming stock ID, it gets removed before adding the new one. The constraint limiting total rows per stock (one unreplied plus one replied) is enforced elsewhere in the submission logic. A fresh row object is created with the message's timestamp and stock ID, leaving qty and price null until the user responds.
> 
> The new row appends to the list, and the unreplied map updates to track it. To maintain a FIFO queue capped at 300 items, older rows are removed from the front when the limit is exceeded, with corresponding cleanup in both tracking maps.
> 
> When a user submits a row, the submission data (quantity, price, TTL, expiry flag) gets processed. The system needs to identify which row was submitted—either through the stockId included in the submission or by tracking the currently edited row. The row data state then updates accordingly, referencing the unreplied and replied maps along with the TTL tracker to manage the submission.
> 
> The unreplied row for that stockId is located first. If no unreplied row exists, a warning logs and the function returns early. Any existing replied row for the same stockId gets removed from the data and its TTL entry is cleaned up. Then the row itself is updated with the new submission values.
> 
> The tracking maps are adjusted to reflect the state change—removing the stockId from unreplied and adding it to replied. If a TTL should apply (non-expiry orders with a defined TTL), an expiration timestamp and unique order ID are stored in the tracker for later cleanup.
> 
> A separate effect manages TTL expirations by checking the tracker at regular intervals. When orders exceed their expiration time, they're collected and removed from the row data, with corresponding cancellation callbacks triggered. it, setRowData };
> }
> ```
> 
> I notice some inefficiencies in the current approach. Using `filter` and `map` repeatedly creates unnecessary arrays, and the FIFO validation with the `while` loop involves multiple array operations. Let me refactor this to be more efficient:
> 
> ```javascript
> const handleMsg = useCallback((msg) => {
>     const { time, stockId } = msg;
>     const id = generateId();
>     
>     setRowData(prev => {
>         const unrepliedMap = unrepliedMapRef.current;
>         const ttlTracker = ttlTrackerRef.current;
>         
>         const newRow = {
>             id,
>             time,
>             stockId,
>             repliedTime: null,
>             qty: null,
>             price: null
>         };
>         
>         const
> ```
> 
> When a message arrives for a stockId that already has an unreplied entry, I'll remove the old one and append the new row to maintain FIFO order. If the stockId is new, I simply append it. After updating the unreplied map, I check if we've exceeded 300 rows and trim from the front, cleaning up the TTL tracker for any removed entries.
> 
> I notice I'm using `splice` which mutates the array directly—that's problematic in React. I should switch to `slice` to create a new array instead, keeping the first `removeCount` items removed and the rest preserved.
> 
> For the cleanup logic, I'm iterating through the removed rows and deleting their corresponding entries from the tracking maps and TTL tracker. This ensures no stale references remain.
> 
> I'm also reconsidering the state management approach. Since `setRowData` uses a functional update pattern, I'm guaranteed the latest state, but the refs are shared across all updates. This could theoretically cause race conditions if updates fire rapidly. However, for this use case where the refs are just auxiliary tracking structures, `useState` with functional updates should work fine—`useReducer` would add unnecessary complexity here.
> 
> There's one edge case I need to verify: when two messages for the same stockId arrive in quick succession. The first creates a row and updates `unrepliedMap`, then the second finds that entry and replaces it. Since React batches updates and processes functional updates sequentially, the second `setRowData` callback receives the correct previous state including the first message's row. The ref mutations happen in the right order, so this should handle correctly. pliedMap still points to... hmm.
> 
> Let me think more carefully about the timing. When handleMsg(msg1) is called, setRowData gets queued with callback1, but it doesn't execute yet. Then handleMsg(msg2) runs and queues callback2. React processes them in order: callback1 runs first with prev=[], produces [rowA], and updates unrepliedMap[stock]=A. Then callback2 runs with prev=[rowA], reads the now-correct unrepliedMap[stock]=A, removes A, and produces [rowB].
> 
> The key insight is that unrepliedMap updates happen inside the setRowData callback, so they execute sequentially. When handleMsg({stockId: 'A'}) is called, it generates an id and queues the callback. That callback will check unrepliedMap.get('A'), find it undefined initially, create a new row with that id, append it, and set unrepliedMap.set('A', id). The callbacks run in order, so the map gets updated before the next callback needs to read it. callback1 executes first, setting unrepliedMap.get('A') to undefined initially, then creating row 1 and updating the map to 1. When callback2 runs next, it sees unrepliedMap.get('A') as 1, filters out the old row, creates row 2, and updates the map again. Since refs are mutable objects, each callback observes the mutations from the previous one, so the sequential processing handles rapid calls correctly.
> 
> The solution needs a rowDataManager that uses refs to track pending requests and generates unique IDs for each row update. Data, setRowData] = useState([]);
>     
>     // O(1) lookup maps
>     const unrepliedMapRef = useRef(new Map()); // stockId -> row.id
>     const repliedMapRef = useRef(new Map());   // stockId -> row.id
>     
>     // TTL tracking: row.id -> { expiresAt, orderId }
>     const ttlTrackerRef = useRef(new Map());
>     
>     const handleMsg = useCallback((msg) => {
>         const { time, stockId } = msg;
>         const id = generateId();
>         
>         setRowData(prev => {
>             const unrepliedMap = unrepliedMapRef.current;
>             const repliedMap = repliedMapRef.current;
>             const ttlTracker = ttlTrackerRef.current;
>             
>             // If there's already an unreplied entry for this stock, remove it first
>             const existingUnrepliedId = unrepliedMap.get(stockId);
>             let next = existingUnrepliedId !== undefined 
>                 ? prev.filter(row => row.id !== existingUnrepliedId)
>                 : prev.slice();
>             
>             // Insert the new row with initial state
>             next.push({
>                 id,
>                 time,
>                 stockId,
>                 repliedTime: null,
>                 qty: null,
>                 price: null
>             });
>             
>             unrepliedMap.set(stockId, id);
>             
>             // Maintain FIFO ordering by trimming to 300 rows maximum
>             if (next.length > 300) {
>                 const excess = next.length -
> 
> 300;
>                 const removed = next.slice(0, excess);
>                 next = next.slice(excess);
>                 
>                 // Clean up maps for removed rows
>                 for (const row of removed) {
>                     if (unrepliedMap.get(row.stockId) === row.id) {
>                         unrepliedMap.delete(row.stockId);
>                     }
>                     if (repliedMap.get(row.stockId) === row.id) {
>                         repliedMap.delete(row.stockId);
>                     }
>                     ttlTracker.delete(row.id);
>                 }
>             }
>             
>             return next;
>         });
>     }, []);
>     
>     const onRowSubmit = useCallback((submission) => {
>         const { stockId, qty, price, ttl, isExpiry } = submission;
>         const repliedTime = Date.now();
>         
>         setRowData(prev => {
>             const unrepliedMap = unrepliedMapRef.current;
>             const repliedMap = repliedMapRef.current;
>             const ttlTracker = ttlTrackerRef.current;
>             
>             // Find the unreplied row ID
>             const rowId = unrepliedMap.get(stockId);
>             if (rowId === undefined) {
>                 return prev; // No unreplied row found
>             }
>             
>             // Check for existing replied row to remove
>             const existingRepliedId = repliedMap.get(stockId);
>             
>             // Build new array: remove old replied, update the submitted row
>             const next = [];
>             for (const row of prev) {
>                 if (row.id === existingRepliedId) {
>                     ttlTracker.delete(existingRepliedId);
>                     continue;
>                 }
>                 if (row.id === rowId) {
>                     next.push({
>                         ...row,
>                         repliedTime,
>                         qty,
>                         price
>                     });
>                 } else {
>                     next.push(row);
>                 }
>             }
>             
>             // Update maps
>             unrepliedMap.delete(stockId);
>             repliedMap.set(stockId, rowId);
>             
>             // Set TTL if applicable
>             if (!isExpiry && ttl > 0) {
>                 ttlTracker.set(rowId, {
>                     expiresAt: Date.now() + ttl * 1000,
>                     orderId: `order_${
> 
> I'm iterating through the rows to skip any old replied entry for this stock and update the current row with the new replied time and quantities. Then I'm updating the tracking maps to move this stock from unreplied to replied status, and setting up a TTL expiration timer if needed. orderId } of expired) {
>                 try {
>                     cancelOrder(orderId);
>                 } catch (e) {
>                     console.error('Failed to cancel order:', orderId, e);
>                 }
>             }
>             
>             // Remove from state and clean up
>             const expiredIdSet = new Set(expired.map(e => e.rowId));
>             
>             setRowData(prev => {
>                 const next = prev.filter(row => {
>                     if (expiredIdSet.has(row.id)) {
>                         repliedMap.delete(row.stockId);
>                         ttlTracker.delete(row.id);
>                         return false;
>                     }
>                     return true;
>                 });
>                 return next;
>             });
>         }, 1000);
>         
>         return () => clearInterval(checkInterval);
>     }, [cancel
> 
> For each expired entry, I attempt to cancel the order and handle any errors. Then I filter out the expired rows from state while cleaning up the tracking maps by removing their stockId and rowId references. // Remove expired entries from ttlTracker first to avoid duplicate processing
>         for (const { rowId } of expired) {
>             ttlTracker.delete(rowId);
>         }
>         
>         // Trigger cancellations for each expired order
>         for (const { orderId } of expired) {
>             cancelOrder(orderId);
>         }
>         
>         // Update state to remove the expired rows and clean up repliedMap
>         const expiredIdSet = new Set(expired.map(e => e.rowId));
>         setRowData(prev => {
>             const repliedMap = repliedMapRef.current;
>             return prev.filter(row => {
>                 if (expiredIdSet.has(row.id)) {
>                     repliedMap.delete(row.stockId);
>                     return false;
>                 }
>                 return true;
>             });
>         });
>     },
> 
> I'm clearing the TTL tracker entries upfront to prevent the same orders from being cancelled multiple times, then calling cancelOrder for each one, and finally filtering them out of the state while cleaning up the replied map references. This is correct!
> 
> When a row is removed by FIFO instead of TTL expiration, we clean up the ttlTracker entry but don't trigger cancelOrder since it wasn't a timeout. If onRowSubmit gets called for a stockId without an unreplied row, we exit early—potentially logging a warning. When submitting a row that already has a replied counterpart, the old replied row gets removed and its TTL cleaned up appropriately. Submitting the same row twice fails safely on the second attempt since the unreplied entry no longer exists. The order ID format using `order_${stockId}_${rowId}` ensures uniqueness since rowId increments independently. The server likely manages its own TTL independently, so I'll just clear the interval on unmount without worrying about canceling pending orders.
> 
> I could also offer a class-based alternative for different architectural needs, with methods to generate IDs, track TTLs across replied and unreplied maps, and notify subscribers of state changes.
> 
> However, since the user is working with React and hooks, the hook-based approach fits better. I'll add TypeScript-style JSDoc annotations to make the row structure clearer—tracking the ID, server timestamp, stock identifier, reply status, and quantity entered.
> 
> The submission object needs to capture what the user enters in the dialog: the stock ID, quantity, price, time-to-live duration, and whether expiration is disabled. When the user double-clicks a row and submits the dialog, the callback receives the row with these new fields populated. The `row` parameter passed to `onRowSubmit` combines the original row data with user inputs. I need to destructure it to get the row identifier and new values like `qty`, `price`, `ttl`, and `isExpiry`.
> 
> In the handler, I'll verify the row is still the current unreplied one for that stock by checking against the `unrepliedMap`, then update the data accordingly using the refs to track state across renders.
> 
> When building the new array, I remove any existing replied row for that stock from `ttlTracker`, update the current row with the new values and timestamp, and keep everything else unchanged. After that, I update both maps to mark this row as replied and remove it from unreplied, then set up the TTL tracking for expiration. Looking at the requirements, I need to provide a complete solution that integrates with their existing setup. They already have the display component and websocket handling, so I should focus on the core logic: managing rowData with the 300-item limit and FIFO behavior, implementing handleMsg to add incoming messages, handling order submissions, and managing TTL expiration.
> 
> I'll structure this as a custom hook they can drop into their code. The hook will track unreplied and replied orders separately, enforce the size constraints, and handle automatic expiration of orders based on TTL. The Dialog component receives the onRowSubmit callback to handle form submissions. Looking at the performance requirements, I need to separate concerns: rowData should only hold display fields (time, stockId, repliedTime, qty, price), while TTL and expiry status live in separate data structures to minimize memory overhead. This approach avoids unnecessary re-renders and keeps the event loop clean by using efficient data structures rather than relying on setTimeout for expiration checks. d for this:
> - rowData only has display fields
> - TTL info is in ttlTrackerRef (Map keyed by rowId)
> - Single interval instead of multiple setTimeouts
> 
> A min-heap could optimize expiration checking, but with a max of 300 rows and only TTL-enabled ones tracked, iterating through the Map works fine.
> 
> For frequent updates, batching could reduce re-renders, though React 18's built-in batching handles this reasonably well without added complexity.
> 
> The implementation should handle the core use cases, including cleanup when rows are removed.

# Row Data Manager Implementation

Based on your requirements, I'll create an efficient solution with proper data structures for high-performance scenarios.

## Key Design Decisions:

1. **Separate tracking maps** (stored in refs) for O(1) lookups instead of array searches
2. **Single interval** for TTL checks instead of multiple `setTimeout` calls
3. **TTL data stored separately** from `rowData` as requested
4. **Unique ID per row** for accurate tracking

```javascript
// useRowDataManager.js
import { useCallback, useEffect, useRef, useState } from 'react';

// Unique ID generator (simple incrementing counter for performance)
let idCounter = 0;
const generateId = () => ++idCounter;

/**
 * Custom hook to manage row data with constraints:
 * - Max 300 items (FIFO)
 * - Max 1 unreplied row per stockId
 * - Max 2 rows per stockId (1 unreplied + 1 replied)
 * - TTL-based auto-removal for replied rows
 * 
 * @param {Function} cancelOrder - Function to call when TTL expires
 * @returns {{ rowData: Array, handleMsg: Function, onRowSubmit: Function }}
 */
export function useRowDataManager(cancelOrder) {
    const [rowData, setRowData] = useState([]);
    
    // ============ Performance-optimized tracking structures ============
    // These are stored in refs to avoid re-renders and provide O(1) lookups
    
    // stockId -> rowId (for unreplied rows)
    const unrepliedMapRef = useRef(new Map());
    
    // stockId -> rowId (for replied rows)
    const repliedMapRef = useRef(new Map());
    
    // rowId -> { expiresAt: number, orderId: string }
    // Stored separately from rowData as per requirements
    const ttlTrackerRef = useRef(new Map());
    
    // ============ Handle incoming WebSocket message ============
    const handleMsg = useCallback((msg) => {
        const { time, stockId } = msg;
        const newRowId = generateId();
        
        setRowData(prev => {
            const unrepliedMap = unrepliedMapRef.current;
            const repliedMap = repliedMapRef.current;
            const ttlTracker = ttlTrackerRef.current;
            
            // Check for existing unreplied row for this stockId
            const existingUnrepliedId = unrepliedMap.get(stockId);
            
            let next;
            if (existingUnrepliedId !== undefined) {
                // Remove the old unreplied row (keep all others)
                next = [];
                for (let i = 0; i < prev.length; i++) {
                    if (prev[i].id !== existingUnrepliedId) {
                        next.push(prev[i]);
                    }
                }
            } else {
                // No existing unreplied, just copy the array
                next = prev.slice();
            }
            
            // Create and append new row (only display fields)
            next.push({
                id: newRowId,
                time,
                stockId,
                repliedTime: null,
                qty: null,
                price: null
            });
            
            // Update tracking map
            unrepliedMap.set(stockId, newRowId);
            
            // FIFO: enforce max 300 items
            if (next.length > 300) {
                const excess = next.length - 300;
                const removed = next.slice(0, excess);
                next = next.slice(excess);
                
                // Clean up tracking for removed rows
                for (let i = 0; i < removed.length; i++) {
                    const row = removed[i];
                    if (unrepliedMap.get(row.stockId) === row.id) {
                        unrepliedMap.delete(row.stockId);
                    }
                    if (repliedMap.get(row.stockId) === row.id) {
                        repliedMap.delete(row.stockId);
                    }
                    // Clean TTL but don't call cancelOrder (FIFO removal, not TTL expiry)
                    ttlTracker.delete(row.id);
                }
            }
            
            return next;
        });
    }, []);
    
    // ============ Handle row submission (user replied) ============
    const onRowSubmit = useCallback((row) => {
        // row contains: id (or can use stockId), qty, price, ttl, isExpiry
        const { stockId, qty, price, ttl, isExpiry } = row;
        const repliedTime = Date.now();
        
        setRowData(prev => {
            const unrepliedMap = unrepliedMapRef.current;
            const repliedMap = repliedMapRef.current;
            const ttlTracker = ttlTrackerRef.current;
            
            // Find the unreplied row for this stockId
            const rowId = unrepliedMap.get(stockId);
            if (rowId === undefined) {
                // No unreplied row found - this shouldn't happen in normal flow
                console.warn(`No unreplied row found for stockId: ${stockId}`);
                return prev;
            }
            
            // Check for existing replied row (will be replaced)
            const existingRepliedId = repliedMap.get(stockId);
            
            // Build new array in single pass
            const next = [];
            for (let i = 0; i < prev.length; i++) {
                const r = prev[i];
                
                // Skip old replied row (being replaced)
                if (r.id === existingRepliedId) {
                    // Clean up old TTL without calling cancelOrder (explicit replacement)
                    ttlTracker.delete(existingRepliedId);
                    continue;
                }
                
                // Update the submitted row
                if (r.id === rowId) {
                    next.push({
                        id: r.id,
                        time: r.time,
                        stockId: r.stockId,
                        repliedTime,
                        qty,
                        price
                    });
                } else {
                    next.push(r);
                }
            }
            
            // Update tracking maps
            unrepliedMap.delete(stockId);
            repliedMap.set(stockId, rowId);
            
            // Set up TTL if applicable (isExpiry=false means row CAN expire)
            if (!isExpiry && ttl > 0) {
                ttlTracker.set(rowId, {
                    expiresAt: Date.now() + ttl * 1000,
                    orderId: `order_${stockId}_${rowId}_${repliedTime}`
                });
            }
            
            return next;
        });
    }, []);
    
    // ============ Single interval for TTL expiration checks ============
    // Using one interval instead of multiple setTimeout for better performance
    useEffect(() => {
        const intervalId = setInterval(() => {
            const ttlTracker = ttlTrackerRef.current;
            const now = Date.now();
            
            // Find all expired entries
            const expired = [];
            for (const [rowId, data] of ttlTracker) {
                if (now >= data.expiresAt) {
                    expired.push({ rowId, orderId: data.orderId });
                }
            }
            
            // Early exit if nothing expired
            if (expired.length === 0) return;
            
            // Remove from TTL tracker immediately to prevent double-processing
            for (let i = 0; i < expired.length; i++) {
                ttlTracker.delete(expired[i].rowId);
            }
            
            // Call cancelOrder for each expired row
            for (let i = 0; i < expired.length; i++) {
                try {
                    cancelOrder(expired[i].orderId);
                } catch (e) {
                    console.error('Failed to cancel order:', expired[i].orderId, e);
                }
            }
            
            // Remove expired rows from state
            const expiredIdSet = new Set(expired.map(e => e.rowId));
            
            setRowData(prev => {
                const repliedMap = repliedMapRef.current;
                const next = [];
                
                for (let i = 0; i < prev.length; i++) {
                    const row = prev[i];
                    if (expiredIdSet.has(row.id)) {
                        // Clean up replied map
                        repliedMap.delete(row.stockId);
                    } else {
                        next.push(row);
                    }
                }
                
                return next;
            });
        }, 1000); // Check every second
        
        return () => clearInterval(intervalId);
    }, [cancelOrder]);
    
    return { rowData, handleMsg, onRowSubmit };
}
```

## Usage Example:

```javascript
import { useRowDataManager } from './useRowDataManager';

function TradingComponent() {
    // Your cancel order API function
    const cancelOrder = useCallback((orderId) => {
        fetch(`/api/orders/${orderId}/cancel`, { method: 'POST' });
    }, []);
    
    const { rowData, handleMsg, onRowSubmit } = useRowDataManager(cancelOrder);
    
    // Connect to WebSocket
    useEffect(() => {
        const ws = new WebSocket('wss://your-server/stream');
        ws.onmessage = (event) => {
            const msg = JSON.parse(event.data);
            handleMsg(msg);
        };
        return () => ws.close();
    }, [handleMsg]);
    
    // Your existing table component
    return (
        <>
            <YourTableComponent 
                data={rowData} 
                onRowDoubleClick={(row) => openDialog(row)} 
            />
            <YourDialogComponent onSubmit={onRowSubmit} />
        </>
    );
}
```

## Performance Summary:

| Operation | Time Complexity | Notes |
|-----------|-----------------|-------|
| `handleMsg` | O(n) worst case | Only when removing existing unreplied row |
| `onRowSubmit` | O(n) | Single pass through array |
| TTL check | O(k) | k = number of rows with TTL |
| stockId lookup | O(1) | Using Map |

## Memory Optimization:

- `rowData` stores only display fields (`time`, `stockId`, `repliedTime`, `qty`, `price`)
- TTL/expiry data stored in separate `ttlTrackerRef` Map
- Single interval timer instead of multiple `setTimeout` calls
- Uses `for` loops instead of array methods where performance matters