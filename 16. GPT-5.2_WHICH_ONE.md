## Verdict

**Solution 2 is the better (and basically the only) starting point for your requirements.**  
**Solution 1 is not just “slower vs faster” — it’s functionally mismatched and has serious correctness/performance problems that will bite under load.**

For “very high performance” (high WS rate), **Solution 2 still needs one key change**: **don’t call `setState` (`flush()`) on every message**. Batch UI updates (e.g., 1 render per animation frame).

---

## Why Solution 1 is *not* the right choice (and can degrade badly)

### 1) It doesn’t implement your domain rules
Your rules are *per `stockId`*:
- only **one unreplied** row per `stockId`
- max **two rows per `stockId`** (one unreplied + one replied)
- submit updates + TTL expiry removal + cancel request

Solution 1 is a generic “update-by-id” stream table. It never enforces those `stockId` constraints or TTL behavior.

### 2) The heap logic is broken with mutable objects
It pushes the **same row object reference** into the heap repeatedly and then **mutates `row.timestamp`**.

That breaks heap invariants because heap ordering depends on `timestamp`, and you’re changing it *after insertion* (and across multiple heap entries pointing to the same object).

### 3) The heap grows without bound (real perf/memory risk)
Every update does `pushToHeap(existingRow)` again. Even if `map.size` stays at 300, **`heap.length` grows forever** under a hot stream. That will eventually dominate CPU and memory.

### 4) Rendering approach is wasteful / incorrect
- It runs a perpetual `requestAnimationFrame` loop even when idle (avoidable).
- It mutates row objects, and then uses `React.memo` row components → **memoized rows won’t re-render** because the prop object identity didn’t change.

### 5) FIFO requirement mismatch
You want **FIFO cap of 300**. Solution 1 removes “oldest by (mutating) timestamp”, not strict FIFO arrival order.

---

## Why Solution 2 is closer and will be faster in practice

Solution 2 already has the right “shape” for your rules:

- `unrepliedRef: Map<stockId,row>` → enforce **one unreplied per stock**
- `repliedRef: Map<stockId,row>` → enforce **one replied per stock**
- global `rowsRef: Array` capped to **300 FIFO**
- TTL uses **a single timer** scheduled for the next expiry (good: minimal timers)

For `N <= 300`, the “linear” operations (`indexOf`, `splice`, `shift`) are bounded and typically cheap. The real bottleneck for “very high performance” is **React rendering**, not those `O(300)` array ops.

---

## The one change Solution 2 needs for “very high performance”: batch renders

Right now Solution 2 calls `flush()` on every `handleMsg`. If messages arrive at 200–2000/sec, that means **200–2000 React renders/sec** → you’ll drop frames.

Instead: keep all the ref-based logic, but replace `flush()` with **“schedule one flush per frame”**:

```js
const rafRef = useRef(0);
const dirtyRef = useRef(false);

const requestFlush = useCallback(() => {
  dirtyRef.current = true;
  if (rafRef.current) return;

  rafRef.current = requestAnimationFrame(() => {
    rafRef.current = 0;
    if (!dirtyRef.current) return;
    dirtyRef.current = false;
    setDisplayRows(rowsRef.current.slice());
  });
}, []);
```

Then call `requestFlush()` instead of `flush()` in:
- `handleMsg`
- `onRowSubmit`
- `processExpiries` (only if something changed)

And on unmount, cancel the RAF if needed.

This gives you the same “render at most ~60fps” benefit Solution 1 *tries* to provide, without Solution 1’s heap/pool issues.

---

## Summary

- **Pick Solution 2** (it matches the functional requirements and is structurally efficient).
- **Do not use Solution 1 as written** (broken heap semantics, unbounded heap growth, wrong memo/render behavior, missing requirements).
- To meet “very high performance” needs, **throttle React updates** (RAF-scheduled flush). This is the single biggest win.

If you tell me your expected websocket rate (msgs/sec) and whether the table rows are memoized/virtualized, I can recommend whether you should also:
- avoid `shift()` via a ring buffer, or
- keep/remove the heap in favor of a simple `Map` scan for expiries (often enough when active rows ≤ 300).