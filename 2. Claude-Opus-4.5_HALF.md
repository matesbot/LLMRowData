*Thinking...*

> Let me analyze this feature request carefully:
> 
> 1. **State management**: `rowData` with max 300 items (FIFO)
> 2. **WebSocket callback**: `handleMsg(msg)` receives messages with `{time, stockId}`
> 3. **Display columns**: time, stockId, repliedTime, qty, price
> 4. **Dialog submission**: `onRowSubmit(row)` with qty, price, ttl, isExpiry
> 5. **Constraints**:
>    - Only one unreplied row per stockId (latest replaces first)
>    - Max 2 rows per stockId (one unreplied + one replied)
> 6. **After submission**:
>    - Update row with repliedTime, qty, price
>    - If `isExpiry` is false and ttl has value, remove row after ttl seconds
>    - Call `cancelOrder()` when ttl triggers
> 
> **Performance considerations**:
> - Minimize setTimeout usage
> - Use efficient data structures
> - Store ttl/isExpiry separately from rowData
> 
> Let me design the solution:
> 
> ### Data Structures
> 
> 1. **rowData**: Array of display items `{time, stockId, repliedTime, qty, price, id}` (need an id for tracking)
> 
> 2. **Tracking structures** (outside rowData for efficiency):
>    - `unrepliedMap`: Map<stockId, rowId> - tracks the latest unreplied row for each stockId
>    - `repliedMap`: Map<stockId, rowId> - tracks the replied row for each stockId
>    - `ttlMap`: Map<rowId, {timerId, ttl, isExpiry}> - stores TTL info separately
> 
> 3. **For timeout management**: Instead of multiple setTimeouts, I could use a single interval that checks for expired items, but that might be less efficient. Actually, for precision, setTimeout per row might be necessary, but we need to clean them up properly.
> 
> Let me reconsider the setTimeout approach:
> 
> 
> - Multiple timers per row are simpler but create overhead
> - A single interval checking all rows wastes CPU constantly
> - A priority queue with one timer firing for the next expiry is most efficient
> 
> Given the 300-item max and that only some rows have TTL, I'll use a min-heap approach with a single setTimeout that reschedules itself for the next expiring item. This minimizes event loop pressure while maintaining precision.
> 
> I need to track rows with unique IDs, maintain maps for unreplied and replied items, store TTL data with expiry times, and implement a heap-based timer system. The core logic will generate row IDs, manage the TTL map, and reschedule the timer whenever the next expiry changes.
> 
> When a message arrives, I'll create a new row and check if an unreplied entry already exists for that stock ID. If one does, I'll remove it from the data and clean up its TTL entry before adding the new row to the unreplied map and scheduling its expiration.
> 
> To maintain the 300-row limit, I'll shift off the oldest entries from the front while cleaning up their corresponding map references. Once the data is trimmed, I'll return the updated array.
> 
> But I need to reconsider the constraints more carefully. The requirement is that each stockId can have at most 2 rows—one unreplied and one replied. When a new message arrives for a stockId that already has an unreplied row, I should remove that old unreplied entry first. If adding a new unreplied row would exceed the 2-row limit for that stockId, I need to remove the oldest row for that stock.
> 
> For handling TTL expiration efficiently without excessive event loop overhead, I should use a single timer with a queue sorted by expiry time rather than individual timers for each row.
> 
> The approach maintains a queue of pending expirations ordered by when they're due. A cleanup function runs periodically to remove items that have already been deleted or expired, then schedules the next timeout based on the earliest remaining item. This way, only one active timer exists at a time, and the cleanup happens lazily rather than constantly polling. = 0, right = ttlQueueRef.current.length;
>     while (left < right) {
>         const mid = (left + right) >> 1;
>         if (ttlQueueRef.current[mid].expiryTime < expiryTime) {
>             left = mid + 1;
>         } else {
>             right = mid;
>         }
>     }
>     ttlQueueRef.current.splice(left, 0, entry);
>     
>     // Reschedule if this is the new earliest
>     if (left === 0) {
>         scheduleNextExpiry();
>     }
> }
> 
> function handleRowExpiry(rowId) {
>     ttlDataRef.current.delete(rowId);
>     cancelOrder(rowId);
>     
>     setRowData(prev => {
>         const newData = prev.filter(row =>
> 
> I'm using binary search to find the correct insertion point in the queue, maintaining sorted order by expiry time. Once inserted, if the new entry becomes the earliest expiration, I reschedule the timer. When a row expires, I clean up its TTL data, cancel the associated order, and remove it from the display. Looking at the next thinking, I need to complete the partial thought about handling the replied map and then continue with the row submission logic.
> 
> When a row is submitted, I'm moving it from unreplied to replied status. If there's already a replied row for that stock, I need to track this - though removing it within the map operation is tricky since I can't easily delete another row during iteration. I'll update the replied map reference to point to the new row ID, then update the current row with the submission timestamp, quantity, and price. After the map completes, I handle the TTL if the row isn't an expiry type.
> 
> The core constraint is that each stockId can have at most one unreplied and one replied row displayed. When a new row becomes replied, I need to consider whether an existing replied row should be removed, though the exact behavior depends on the broader requirements.
> 
> If an unreplied row gets submitted and becomes replied while a replied row already exists for that stockId, we'd exceed the limit. The logical approach is to remove the old replied row when a new one takes its place, maintaining the 1 unreplied + 1 replied maximum per stockId.
> 
> When submitting a row, I need to update its timestamp and values, then move it from the unreplied to replied tracking. If another replied row exists for the same stockId, that older one should be deleted from the data.
> 
> ```javascript
> function onRowSubmit(row) {
>     const now = Date.now();
>     
>     setRowData(prev => {
>         let newData = prev.map(r => {
>             if (r.id === row.id) {
>                 return {
>                     ...r,
>                     repliedTime: now,
>                     qty: row.qty,
>                     price: row.price
>                 };
>             }
>             return r;
>         });
>         
>         const submittedRow = newData.find(r => r.id === row.id);
>         if (submittedRow) {
>             const stockId = submittedRow.stockId;
>             
>             unrepliedMapRef.current.delete(stockId);
>             
>             const existingRepliedId = repliedMapRef.current.get(stockId);
>             if (existingRepliedId !== undefined && existingRepliedId !== row.id) {
>                 newData = newData.filter(r => r.id !== existingRepliedId);
>             }
> ```
> 
> Using refs for tracking works well here since they don't cause re-renders and updates happen synchronously. After updating the state, I'll handle the TTL if needed.
> 
> For cleanup when rows get removed by the FIFO limit, I need to clear them from both the unrepliedMap and repliedMap, plus remove any stale entries from ttlDataRef. The queue itself will naturally handle expired entries, so I don't need to manually cancel timers there.
> 
> Since the user specified that rowData should only contain display fields like time, stockId, repliedTime, qty, and price, I'm correctly keeping TTL and expiry values separate in ttlDataRef rather than storing them in the row objects themselves.
> 
> For identifying orders when calling cancelOrder(), I'll use a simple incrementing counter as the unique ID rather than combining stockId and time. On component unmount, I need to clear any active timers to prevent memory leaks and ensure cleanup happens properly.
> 
> Now I'm setting up the core data structures. I'll use refs for the tracking maps to avoid triggering re-renders when they change. The unrepliedMapRef and repliedMapRef store which row is currently associated with each stock ID, while ttlDataRef tracks expiration times by row ID and ttlQueueRef maintains a sorted queue of expirations. The timerRef holds the current timeout handle. When removing a row, I need to clean up its entries from both tracking maps and the TTL data.
> 
> For scheduling the next expiry, I'll clear any existing timer and process the queue by checking the current time against stored expiration times, skipping entries that have already been removed.
> 
> When an item has expired, I dequeue it, delete its TTL data, cancel the associated order, and filter it from the row data after running cleanup. If an item hasn't expired yet, I calculate the delay until its expiration time and set a new timeout to handle it.
> 
> For adding TTL to a row, I store the expiry time in the ref and use binary search to insert the item into the queue at the correct position based on expiration time.
> 
> When handling an incoming WebSocket message, I create a new row with the message data and a unique ID, then check if there's already an unresolved entry that needs to be updated or if this is a fresh row to add to the data.
> 
> If an existing unreplied row exists for that stockId, I locate and remove it from the data array and clean up its TTL reference. Then I append the new row, update the unreplied map to track this stockId's latest row ID, and enforce the FIFO limit by removing older entries when the queue exceeds capacity. .length > MAX_ROWS) {
>                 const removed = newData.shift();
>                 cleanupRow(removed);
>             }
>             
>             return newData;
>         });
>     }, [cleanupRow]);
>     
>     // Handle row submission
>     const onRowSubmit = useCallback((row) => {
>         const now = Date.now();
>         
>         setRowData(prev => {
>             let newData = [...prev];
>             const idx = newData.findIndex(r => r.id === row.id);
>             
>             if (idx === -1) return prev;
>             
>             const submittedRow = newData[idx];
>             const stockId = submittedRow.stockId;
>             
>             // Update the row
>             newData[idx] = {
>                 ...submittedRow,
>                 repliedTime: now,
>                 qty: row.qty,
>                 price: row.price
>             };
>             
>             // Move from unreplied to replied
>             unrepliedMapRef.current.delete(stockId);
>             
>             // Check if there's already a replied row for this stockId
>             const existingRepliedId = repliedMapRef.current.get(stockId);
>             if (existingRepliedId !== undefined && existingRepliedId !== row.id) {
>                 // Remove the old replied row
>                 const oldIdx = newData.findIndex(r => r.id === existingRepliedId);
>                 if (oldIdx !== -1) {
>                     const oldRow = newData[oldIdx];
>                     newData.splice(oldIdx, 1);
>                     ttlDataRef.current.delete(existingRepliedId);
>                 }
>             }
> 
> When a row is submitted, I update it with the new quantity and price, then mark it as replied by removing it from the unreplied tracking map. If another replied row already exists for that stock, I remove the older one to keep only the most recent response. I need to reconsider the expiry logic. The `isExpiry` field represents a "no expiry" checkbox, so when it's false, the row should actually expire after the TTL period. The condition checks if expiry is disabled and a TTL value exists, then schedules the row for removal using the `addTTL` function.
> 
> For performance, I should be mindful about avoiding unnecessary array allocations and keeping operations efficient.
> 
> Map-based lookups for tracking replied/unreplied orders are O(1), which is good. A TTL queue with binary insertion gives O(log n) insertion and O(1) removal from the front. Using a single timer instead of multiple timers per order reduces overhead. Storing data in refs rather than state prevents unnecessary re-renders.
> 
> There are a few edge cases to consider: if the same row gets submitted multiple times, the maps will handle it since I check the ID. If a row is removed from the FIFO queue before submission, the handler will exit early when it can't find the row. If an order expires while the dialog is still open, the row gets removed from the queue.
> 
> The implementation should work well. The user already has the component for displaying rowData and the WebSocket connection ready, so I need to focus on the state management logic—specifically handleMsg and onRowSubmit—along with the data structure setup and any necessary cleanup. A custom hook is the right approach here since it encapsulates all the logic cleanly. One important thing: the user's example showed `rowData.push(msg)`, but that's direct mutation, which breaks React's immutability rules. I need to ensure the implementation uses proper immutable patterns instead.
> 
> The incoming message structure only has time and stockId, but the display needs additional fields like repliedTime, qty, and price. I'm initializing these as null when the message arrives. I also need an id field for tracking purposes—including it in the row object itself keeps things simple and lets the display component use it as a key if needed. When the TTL timer expires, I'll call `cancelOrder()` with that unique identifier. Since this is a custom hook, the state resets on unmount, so that concern is handled. The solution looks solid—the while loop processes all rows expiring at the same time before scheduling the next timer, and `clearTimeout` properly handles rescheduling. JavaScript's single-threaded nature means multiple rapid calls to `scheduleNextExpiry` won't cause race conditions; each one clears the existing timer before setting a new one.
> 
> The binary search insertion maintains ascending order correctly by finding the first position where `queue[pos].expiryTime >= expiryTime`. I'm ready to write out the final implementation, though I should note that `shift()` is O(n) for arrays—with a large queue, a more efficient data structure might be worth considering.
> 
> Given the constraint of 300 rows maximum, the current sorted array approach with `shift()` is acceptable. When processing stale entries, we skip them and continue removing from the front, keeping the array sorted. I'll add JSDoc comments for clarity while staying in JavaScript, and wrap the callback functions like `handleMsg` and `onRowSubmit` in `useCallback` since they're passed as dependencies.
> 
> ```javascript
> import { useState, useRef, useCallback, useEffect } from 'react';
> 
> const MAX_ROWS = 300;
> 
> let rowIdCounter = 0;
> 
> /**
>  * Custom hook for managing row data with WebSocket messages and TTL
>  */
> export function useRowDataManager() {
>     const [rowData, setRowData] = useState([]);
>     
>     // Tracking maps for quick lookups
>     const unrepliedMapRef = useRef(new Map()); // stockId -> rowId
>     const repliedMapRef = useRef(new Map()); // stockId -> rowId
>     
>     // TTL management - stored separately from rowData for performance
>     const ttlDataRef = useRef(new Map()); //
> ```
> 
> I need to track expiry times by row ID and maintain a sorted queue of expirations. The timer reference holds the cleanup interval. When removing rows, I clean up all associated tracking data across the maps to prevent memory leaks and stale references.
> 
> The expiry scheduler clears any existing timer, then processes the queue by checking if entries are still valid and handling expired ones. It shifts through the queue to find the next pending expiration, skipping any entries that have already been removed.
> 
> When an entry has expired, it deletes the TTL data, calls the cancel order API, and removes the corresponding row from state while cleaning up any related stock ID mappings. For entries not yet expired, it calculates the remaining delay and sets a new timeout to trigger the next check.
> 
> The `addTTL` function uses binary search to efficiently insert rows into the expiry queue at O(log n) complexity, calculating the expiry timestamp and finding the correct position before splicing the entry into the queue.
> 
> When a new entry is inserted at the front of the queue, the expiry timer gets rescheduled to account for the earlier deadline.
> 
> The `handleMsg` callback processes incoming WebSocket messages by generating a unique row ID and extracting timing and stock information, then updating the row data while tracking which entries are awaiting replies for each stock.
> 
> The function filters out any existing unreplied entry for that stock ID, removes its TTL tracking, and inserts the new message row with initialized fields for reply time, quantity, and price. It updates the unreplied map to point to this new row, then enforces the maximum row limit by removing oldest entries and cleaning up their associated tracking maps. return newData;
>         });
>     }, [cleanupRowMaps]);
>     
>     // Handle row submission (double-click dialog submit)
>     const onRowSubmit = useCallback((row) => {
>         const now = Date.now();
>         const { id, qty, price, ttl, isExpiry } = row;
>         
>         setRowData(prev => {
>             const idx = prev.findIndex(r => r.id === id);
>             if (idx === -1) return prev; // Row not found
>             
>             const submittedRow = prev[idx];
>             const stockId = submittedRow.stockId;
>             
>             // Check for existing replied row for this stockId
>             const existingRepliedId = repliedMapRef.current.get(stockId);
>             
>             let newData;
>             if (existingRepliedId !== undefined && existingRepliedId !== id) {
>                 // Remove old replied row
>                 newData = prev.filter((r, i) => {
>                     if (r.id === existingRepliedId) {
>                         ttlDataRef.current.delete(r.id);
>                         return false;
>                     }
>                     return true;
>                 });
>                 // Find new index after removal
>                 const newIdx = newData.findIndex(r => r.id === id);
>                 newData[newIdx] = {
>                     ...newData[newIdx],
>                     repliedTime: now,
>                     qty,
>                     price
>                 };
>             } else {
>                 newData = [...prev];
>                 newData[idx] = {
>                     ...prev[idx],
>                     repliedTime: now,
>                     qty,
>                     price
>                 };
>             }
>             
>             repliedMapRef.current.set(stockId, id);
>             return newData;
>         });
>     }, [cleanupRowMaps]);
> 
> When a row is submitted, I check if there's already a replied entry for that stock. If one exists and it's different from the current row, I filter it out and clean up its TTL data, then update the new row with the submission timestamp and values. Otherwise, I just update the row in place. Either way, I track the replied row ID in the ref. console.log('Cancelling order:', orderId);
>     // Example: fetch('/api/orders/' + orderId + '/cancel', { method: 'POST' });
> }
> 
> I'm noticing the `onRowSubmit` function receives a `row` object with `qty`, `price`, `ttl`, and `isExpiry`, but there's a gap—how do I know which row was edited? The dialog must somehow track which row triggered it, likely through the row's ID or index when the double-click event fires.
> 
> Since the user mentions the dialog callback provides the submitted data, I'll assume the `row` parameter includes an identifier like `id` or a combination of `stockId` and `time` to distinguish it from other rows. I'll use `row.id` as the identifying field.
> 
> The submitted row should contain the edited fields (`qty`, `price`, `ttl`, `isExpiry`) along with whatever identifier was captured when the dialog opened. I'll structure the callback to handle this row object directly, treating it as having both the identity information and the form data needed to update the table.
> 
> For performance with a large row count, searching through the array each time a message arrives could become inefficient. Storing row indices in the map alongside the row data would help avoid repeated lookups, though managing index shifts when rows are added or removed would require careful handling.
> 
> Since the display component already expects an array format, I'll stick with the current approach—O(n) operations on 300 items should perform adequately. The message handler already iterates efficiently in a single pass, and user submissions happen infrequently enough that further optimization there isn't necessary.
> 
> For ID generation, a simple counter is sufficient since JavaScript safely handles integers up to 2^53 - 1, making UUID overhead unnecessary. The row objects contain only primitive values and plain objects, so they'll serialize properly with the existing table component. I'm ready to write the final implementation with clear comments.
> 
> I'll keep `useCallback` for referential stability in case these functions are passed as props. The TTL queue uses lazy cleanup—when rows are removed, I delete them from `ttlDataRef` and `scheduleNextExpiry` skips stale entries, which is efficient and reliable.
> 
> Here's the implementation:
> 
> ```javascript
> import { useState, useRef, useCallback, useEffect } from 'react';
> 
> const MAX_ROWS = 300;
> let rowIdCounter = 0;
> 
> /**
>  * Custom hook for managing row data with high-performance requirements
>  * 
>  * Features:
>  * - Handles WebSocket messages with FIFO limit
>  * - Maintains at most 1 unreplied + 1 replied row per stockId
>  * - Efficient TTL management with a single timer
>  * - Stores TTL data separately from display data
>  */
> export function useRowDataManager(cancelOrderFn) {
>     const [rowData, setRowData] = useState([]);
>     
>     // O(1) lookup maps for quick access by stockId
>     const unrepliedMapRef = useRef(new Map()); // stockId -> rowId
>     const repliedMapRef = useRef(new Map()); // stockId -> rowId
>     
>     // TTL management with single timer approach
>     // TTL data stored separately from rowData for performance
>     const ttlDataRef = useRef(
> 
> new Map()); // rowId -> expiryTime
>     const ttlQueueRef = useRef([]); // Sorted by expiryTime (ascending)
>     const timerRef = useRef(null);
>     
>     // Process TTL queue and schedule next expiry
>     const scheduleNextExpiry = useCallback(function processQueue() {
>         // Clear existing timer
>         if (timerRef.current !== null) {
>             clearTimeout(timerRef.current);
>             timerRef.current = null;
>         }
>         
>         const now = Date.now();
>         const queue = ttlQueueRef.current;
>         
>         while (queue.length > 0) {
>             const { rowId, expiryTime } = queue[0];
>             
>             // Skip cancelled/removed entries (lazy cleanup)
>             if (!ttlDataRef.current.has(rowId)) {
>                 queue.shift();
>                 continue;
>             }
>             
>             // If not expired yet, schedule timer for next expiry
>             if (expiryTime > now) {
>                 const delay = expiryTime - now;
>                 timerRef.current = setTimeout(processQueue, delay);
>                 return;
>             }
>             
>             // Remove expired row
>             queue.shift();
>             ttlDataRef.current.delete(rowId);
>             setRowData(prev => prev.filter(row => row.id !== rowId));
>         }
>     }, []);
> ```
> 
> I'm setting up the TTL queue processing with a single timer that handles expiries efficiently. The approach uses lazy cleanup for cancelled entries and only schedules the next timeout when there are pending expirations. Once an entry expires, it's removed from both the TTL tracking and the display data. the next expiry time and set up a timer to process the queue when that time arrives.
> 
> The `addTTL` function handles inserting new items into the queue using binary search for efficient O(log n) insertion. It calculates the expiry timestamp, stores it in the ref, then finds the correct position in the queue based on expiry time.
> 
> When a WebSocket message arrives, I extract the row ID and stock information, then update the row data by removing any existing unreplied message for that stock ID before adding the new one.
> 
> I also need to clean up the TTL tracking for replaced rows and enforce the maximum row limit by removing oldest entries when necessary, updating the unreplied map accordingly. ittedRow;
>             const existingRepliedId = repliedMapRef.current.get(stockId);
>             
>             const newData = [];
>             for (let i = 0; i < prev.length; i++) {
>                 const r = prev[i];
>                 if (r.id === existingRepliedId && existingRepliedId !== id) {
>                     ttlDataRef.current.delete(r.id);
>                     continue;
>                 }
>                 if (r.id === id) {
>                     newData.push({
>                         ...r,
>                         repliedTime: now,
>                         qty,
>                         price
>                     });
>                 } else {
>                     newData.push(r);
>                 }
> 
> I'm checking if there's already a replied entry for this stock and removing it if it's different from the current submission. Then I iterate through the data, skipping the old replied row and updating the submitted row with the new quantity, price, and timestamp.
> 
> After building the new array, I update the ref maps to track which stock has been replied to and clear the unreplied status. If a TTL is set and this isn't an expiry, I add the timeout. Finally, I clean up any pending timers when the component unmounts.
> 
> The hook returns the row data, message handler, and submit callback for the consuming component to wire up. In the trading app, the WebSocket connects the incoming messages to `handleMsg`, while the dialog's submit handler calls `onRowSubmit` with the form data and current row ID.
> 
> The `cancelOrder` function makes a POST request to cancel an order by ID. One thing to clarify: the checkbox is labeled "no expiry" in the UI but maps to `isExpiry` in the data model, so I need to ensure the form submission correctly passes this boolean value along with qty, price, and ttl. The naming convention is confusing here. Based on what the user specified, `isExpiry = false` means the row should expire after the TTL period. I'll stick with that interpretation even though the checkbox label "no expiry" seems to suggest the opposite semantic meaning. The code implements the expiration logic correctly according to the requirement: if `row.isExpiry` is false and `row.ttl` has a value, remove the row after that many seconds. means the order SHOULD expire. The logic `if (!isExpiry && ttl)` handles this correctly.
> 
> I'm confident in this approach. The naming convention is admittedly confusing—`isExpiry` being true actually means "no expiry"—but the code aligns with what the user specified. I'll move forward with this implementation.

# High-Performance Row Data Manager

Based on your requirements, I'll design a solution that optimizes for performance with efficient data structures and minimal timer usage.

## Key Design Decisions

1. **Tracking Maps** (`useRef`) - O(1) lookups for unreplied/replied rows by stockId
2. **Single Timer Approach** - Instead of one `setTimeout` per TTL row, maintain a sorted queue and use a single timer for the next expiry
3. **Lazy TTL Cleanup** - When rows are removed, we just delete from `ttlDataRef`; stale entries in the queue are skipped during processing
4. **TTL data stored separately** - `rowData` only contains display fields; TTL/expiry info stored in refs

## Implementation

```javascript
import { useState, useRef, useCallback, useEffect } from 'react';

const MAX_ROWS = 300;
let rowIdCounter = 0;

/**
 * High-performance row data manager
 * 
 * Data Structures:
 * - unrepliedMap: Map<stockId, rowId> - O(1) lookup for unreplied rows
 * - repliedMap: Map<stockId, rowId> - O(1) lookup for replied rows  
 * - ttlQueue: Sorted array by expiryTime - Single timer for next expiry
 * - ttlData: Map<rowId, expiryTime> - Quick validation for stale queue entries
 */
export function useRowDataManager(cancelOrder) {
    const [rowData, setRowData] = useState([]);
    
    // O(1) lookup maps - stored in refs to avoid re-renders
    const unrepliedMapRef = useRef(new Map()); // stockId -> rowId
    const repliedMapRef = useRef(new Map());   // stockId -> rowId
    
    // TTL management - stored separately from rowData
    const ttlDataRef = useRef(new Map());  // rowId -> expiryTime (for validation)
    const ttlQueueRef = useRef([]);        // [{rowId, expiryTime}] sorted ascending
    const timerRef = useRef(null);         // Single timer reference
    
    // Process TTL queue with single timer approach
    const scheduleNextExpiry = useCallback(function processQueue() {
        if (timerRef.current !== null) {
            clearTimeout(timerRef.current);
            timerRef.current = null;
        }
        
        const now = Date.now();
        const queue = ttlQueueRef.current;
        
        while (queue.length > 0) {
            const { rowId, expiryTime } = queue[0];
            
            // Skip stale entries (lazy cleanup)
            if (!ttlDataRef.current.has(rowId)) {
                queue.shift();
                continue;
            }
            
            if (expiryTime <= now) {
                // Process expired entry
                queue.shift();
                ttlDataRef.current.delete(rowId);
                
                // Cancel order via API
                cancelOrder?.(rowId);
                
                // Remove from rowData
                setRowData(prev => {
                    const row = prev.find(r => r.id === rowId);
                    if (row && repliedMapRef.current.get(row.stockId) === rowId) {
                        repliedMapRef.current.delete(row.stockId);
                    }
                    return prev.filter(r => r.id !== rowId);
                });
                continue;
            }
            
            // Schedule timer for next expiry (single timer)
            timerRef.current = setTimeout(processQueue, expiryTime - now);
            break;
        }
    }, [cancelOrder]);
    
    // Binary insertion into sorted TTL queue - O(log n)
    const addTTL = useCallback((rowId, ttlSeconds) => {
        const expiryTime = Date.now() + ttlSeconds * 1000;
        ttlDataRef.current.set(rowId, expiryTime);
        
        const queue = ttlQueueRef.current;
        let lo = 0, hi = queue.length;
        
        while (lo < hi) {
            const mid = (lo + hi) >>> 1;
            if (queue[mid].expiryTime < expiryTime) {
                lo = mid + 1;
            } else {
                hi = mid;
            }
        }
        
        queue.splice(lo, 0, { rowId, expiryTime });
        
        // Reschedule if this is the earliest expiry
        if (lo === 0) {
            scheduleNextExpiry();
        }
    }, [scheduleNextExpiry]);
    
    // Handle incoming WebSocket message
    const handleMsg = useCallback((msg) => {
        const id = ++rowIdCounter;
        const { time, stockId } = msg;
        
        setRowData(prev => {
            const existingUnrepliedId = unrepliedMapRef.current.get(stockId);
            
            // Single pass: build new array, skip existing unreplied for same stockId
            const newData = [];
            for (let i = 0; i < prev.length; i++) {
                const row = prev[i];
                if (row.id === existingUnrepliedId) {
                    // Remove existing unreplied - replaced by new message
                    ttlDataRef.current.delete(row.id);
                    continue;
                }
                newData.push(row);
            }
            
            // Add new unreplied row at end
            newData.push({
                id,
                time,
                stockId,
                repliedTime: null,
                qty: null,
                price: null
            });
            unrepliedMapRef.current.set(stockId, id);
            
            // FIFO limit enforcement
            while (newData.length > MAX_ROWS) {
                const removed = newData.shift();
                // Cleanup tracking maps
                if (unrepliedMapRef.current.get(removed.stockId) === removed.id) {
                    unrepliedMapRef.current.delete(removed.stockId);
                }
                if (repliedMapRef.current.get(removed.stockId) === removed.id) {
                    repliedMapRef.current.delete(removed.stockId);
                }
                ttlDataRef.current.delete(removed.id);
            }
            
            return newData;
        });
    }, []);
    
    // Handle row submission from dialog
    const onRowSubmit = useCallback((row) => {
        const { id, qty, price, ttl, isExpiry } = row;
        const repliedTime = Date.now();
        
        setRowData(prev => {
            const idx = prev.findIndex(r => r.id === id);
            if (idx === -1) return prev; // Row was removed
            
            const submittedRow = prev[idx];
            const { stockId } = submittedRow;
            const existingRepliedId = repliedMapRef.current.get(stockId);
            
            // Single pass: update submitted row, remove old replied if exists
            const newData = [];
            for (let i = 0; i < prev.length; i++) {
                const r = prev[i];
                
                // Remove old replied row for same stockId
                if (r.id === existingRepliedId && existingRepliedId !== id) {
                    ttlDataRef.current.delete(r.id);
                    continue;
                }
                
                // Update the submitted row
                if (r.id === id) {
                    newData.push({
                        id: r.id,
                        time: r.time,
                        stockId: r.stockId,
                        repliedTime,
                        qty,
                        price
                    });
                } else {
                    newData.push(r);
                }
            }
            
            // Update tracking maps
            unrepliedMapRef.current.delete(stockId);
            repliedMapRef.current.set(stockId, id);
            
            return newData;
        });
        
        // Set TTL if applicable (isExpiry=false means it should expire)
        if (!isExpiry && ttl) {
            addTTL(id, ttl);
        }
    }, [addTTL]);
    
    // Cleanup timer on unmount
    useEffect(() => {
        return () => {
            if (timerRef.current !== null) {
                clearTimeout(timerRef.current);
            }
        };
    }, []);
    
    return { rowData, handleMsg, onRowSubmit };
}
```

## Usage Example

```javascript
// In your component
function TradingComponent() {
    const { rowData, handleMsg, onRowSubmit } = useRowDataManager(cancelOrder);
    
    // Wire up to your existing WebSocket handler
    useEffect(() => {
        // Your existing WebSocket setup
        websocket.onMessage = (msg) => {
            handleMsg(msg); // Just call this with the message
        };
    }, [handleMsg]);
    
    // Wire up to your existing dialog submit
    const handleDialogSubmit = (formData) => {
        onRowSubmit({
            id: currentRowId, // The row that was double-clicked
            qty: formData.qty,
            price: formData.price,
            ttl: formData.ttl,        // default 30
            isExpiry: formData.isExpiry  // "no expiry" checkbox value
        });
    };
    
    return <YourExistingTable data={rowData} />;
}

// Your cancel order API call
function cancelOrder(orderId) {
    fetch(`/api/orders/${orderId}/cancel`, { method: 'POST' });
}
```

## Performance Summary

| Operation | Complexity | Notes |
|-----------|------------|-------|
| Message handling | O(n) | Single array pass, map lookups O(1) |
| Row submission | O(n) | Single array pass |
| TTL insertion | O(log n) | Binary search insertion |
| TTL expiry | O(1) amortized | Queue shift, lazy cleanup |
| Memory for timers | O(1) | Single `setTimeout` at any time |

The design ensures minimal event loop usage by maintaining only one active timer regardless of how many rows have TTL configured.